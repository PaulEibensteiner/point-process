{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "::\n",
      "\n",
      "  %autoreload [-p] [-l] [--hide-errors] [mode]\n",
      "\n",
      "%autoreload => Reload modules automatically\n",
      "\n",
      "%autoreload or %autoreload now\n",
      "Reload all modules (except those excluded by %aimport) automatically\n",
      "now.\n",
      "\n",
      "%autoreload 0 or %autoreload off\n",
      "Disable automatic reloading.\n",
      "\n",
      "%autoreload 1 or %autoreload explicit\n",
      "Reload only modules imported with %aimport every time before executing\n",
      "the Python code typed.\n",
      "\n",
      "%autoreload 2 or %autoreload all\n",
      "Reload all modules (except those excluded by %aimport) every time\n",
      "before executing the Python code typed.\n",
      "\n",
      "%autoreload 3 or %autoreload complete\n",
      "Same as 2/all, but also but also adds any new objects in the module. See\n",
      "unit test at IPython/extensions/tests/test_autoreload.py::test_autoload_newly_added_objects\n",
      "\n",
      "The optional arguments --print and --log control display of autoreload activity. The default\n",
      "is to act silently; --print (or -p) will print out the names of modules that are being\n",
      "reloaded, and --log (or -l) outputs them to the log at INFO level.\n",
      "\n",
      "The optional argument --hide-errors hides any errors that can happen when trying to\n",
      "reload code.\n",
      "\n",
      "Reloading Python modules in a reliable way is in general\n",
      "difficult, and unexpected things may occur. %autoreload tries to\n",
      "work around common pitfalls by replacing function code objects and\n",
      "parts of classes previously in the module with new versions. This\n",
      "makes the following things to work:\n",
      "\n",
      "- Functions and classes imported via 'from xxx import foo' are upgraded\n",
      "  to new versions when 'xxx' is reloaded.\n",
      "\n",
      "- Methods and properties of classes are upgraded on reload, so that\n",
      "  calling 'c.foo()' on an object 'c' created before the reload causes\n",
      "  the new code for 'foo' to be executed.\n",
      "\n",
      "Some of the known remaining caveats are:\n",
      "\n",
      "- Replacing code objects does not always succeed: changing a @property\n",
      "  in a class to an ordinary method or a method to a member variable\n",
      "  can cause problems (but in old objects only).\n",
      "\n",
      "- Functions that are removed (eg. via monkey-patching) from a module\n",
      "  before it is reloaded are not upgraded.\n",
      "\n",
      "- C extension modules cannot be reloaded, and so cannot be\n",
      "  autoreloaded.\n",
      "\n",
      "positional arguments:\n",
      "  mode           blank or 'now' - Reload all modules (except those excluded by\n",
      "                 %aimport) automatically now. '0' or 'off' - Disable automatic\n",
      "                 reloading. '1' or 'explicit' - Reload only modules imported\n",
      "                 with %aimport every time before executing the Python code\n",
      "                 typed. '2' or 'all' - Reload all modules (except those\n",
      "                 excluded by %aimport) every time before executing the Python\n",
      "                 code typed. '3' or 'complete' - Same as 2/all, but also but\n",
      "                 also adds any new objects in the module.\n",
      "\n",
      "options:\n",
      "  -p, --print    Show autoreload activity using `print` statements\n",
      "  -l, --log      Show autoreload activity using the logger\n",
      "  --hide-errors  Hide autoreload errors\n",
      "\u001b[0;31mFile:\u001b[0m      ~/semesterprojekt/.env/lib/python3.10/site-packages/IPython/extensions/autoreload.py"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3 --log\n",
    "%autoreload?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data\n",
    "\n",
    "from utils import *\n",
    "from stpy.borel_set import BorelSet\n",
    "\n",
    "name = \"sensepy/sensepy/benchmarks/data/taxi_data.csv\"\n",
    "Num_data_points = 200\n",
    "# borel set a square with boundaries [-1,1]^2\n",
    "domain = BorelSet(2, bounds=torch.tensor([[-1.0, 1.0], [-1.0, 1.0]]).double())\n",
    "obs, dt, gdf = get_taxi_data(Num_data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Process\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import scipy\n",
    "from stpy.kernels import KernelFunction\n",
    "from tqdm import tqdm\n",
    "from autograd_minimize import minimize\n",
    "import torch\n",
    "from typing import List\n",
    "from naive_ppp_estimator import NaivePPPEstimator\n",
    "\n",
    "\n",
    "kernel_object = KernelFunction(kernel_name=\"squared_exponential\", gamma=0.12, d=2)\n",
    "process = NaivePPPEstimator(kernel_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP by representer theorem with two areas\n",
    "\n",
    "process.load_data(\n",
    "    domain, obs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, down, right, up = gdf.total_bounds\n",
    "n = 30  # discretization\n",
    "k = 3  # number of samples to draw and plot\n",
    "\n",
    "xtest = domain.return_discretization(n)\n",
    "Map = BorelSet(d=2, bounds=torch.tensor([[left, right], [down, up]]).double())\n",
    "xtest_orig = Map.return_discretization(n).cpu().numpy()\n",
    "\n",
    "xx = xtest_orig[:, 0]\n",
    "yy = xtest_orig[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m intensity \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/semesterprojekt/point-process/naive_ppp_estimator.py:59\u001b[0m, in \u001b[0;36mNaivePPPEstimator.fit\u001b[0;34m(self, roi, noise_variance)\u001b[0m\n\u001b[1;32m     57\u001b[0m K \u001b[38;5;241m=\u001b[39m K_approx \u001b[38;5;241m+\u001b[39m noise_variance \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     58\u001b[0m K_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(K)\n\u001b[0;32m---> 59\u001b[0m weights \u001b[38;5;241m=\u001b[39m get_weights(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03my = cp.Variable(len(x))\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mnewobjective = cp.Minimize(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03mreturn y.value\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(weights)\n",
      "File \u001b[0;32m~/semesterprojekt/point-process/naive_ppp_estimator.py:37\u001b[0m, in \u001b[0;36mget_weights\u001b[0;34m(points, a)\u001b[0m\n\u001b[1;32m     35\u001b[0m     area \u001b[38;5;241m=\u001b[39m poly_area(x, y)\n\u001b[1;32m     36\u001b[0m     areas[point_i] \u001b[38;5;241m=\u001b[39m area\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mareas\u001b[49m\n",
      "File \u001b[0;32m~/semesterprojekt/point-process/naive_ppp_estimator.py:37\u001b[0m, in \u001b[0;36mget_weights\u001b[0;34m(points, a)\u001b[0m\n\u001b[1;32m     35\u001b[0m     area \u001b[38;5;241m=\u001b[39m poly_area(x, y)\n\u001b[1;32m     36\u001b[0m     areas[point_i] \u001b[38;5;241m=\u001b[39m area\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mareas\u001b[49m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1698\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:636\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1113\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1091\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:496\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/semesterprojekt/.env/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2197\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2194\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2197\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2199\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/semesterprojekt/.env/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2266\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2264\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2266\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2267\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "intensity = process.fit(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Define a scaling factor for the sizes based on mean values\n",
    "scale_factor = 100  # Adjust this factor as needed for visual clarity\n",
    "\n",
    "# Scatter plot with mean values as size and std as color using viridis colormap\n",
    "scatter = ax.scatter(\n",
    "    xx,\n",
    "    yy,\n",
    "    s=intensity * scale_factor,  # Scale point size by mean values\n",
    "    alpha=1.0,\n",
    "    edgecolor=\"face\",\n",
    "    linewidth=0.0,\n",
    "    marker=\"o\",\n",
    ")\n",
    "\n",
    "ctx.add_basemap(ax, crs=gdf.crs.to_string())\n",
    "\n",
    "# Labeling\n",
    "ax.set_title(\"MAP of intensity\")\n",
    "ax.set_xlabel(\"X-axis\")\n",
    "ax.set_ylabel(\"Y-axis\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean in [0.04894289033170558, 1.2456873777126345] and std in [0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Mean in [{torch.min(mean_values)}, {torch.max(mean_values)}] and std in\"\n",
    "    f\" [{torch.min(std_values)}, {torch.max(std_values)}]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(328.4789, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_integral = process.rate_value(xtest, dt).squeeze(1).mean() * 4.0\n",
    "map_integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got expected num points = 328.47892979552665 while actual points is 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Got expected num points = {map_integral} while actual points is {len(obs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
