{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 15:06:19.658026: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-11 15:06:19.678790: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-11 15:06:19.685099: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-11 15:06:19.702729: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 15:06:20.425657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from stpy.kernels import KernelFunction\n",
    "from stpy.borel_set import BorelSet,HierarchicalBorelSets\n",
    "from stpy.point_processes.poisson_rate_estimator import PoissonRateEstimator\n",
    "import torch \n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from scipy.interpolate import griddata\n",
    "from stpy.point_processes.poisson.poisson import PoissonPointProcess\n",
    "from sensepy.capture_thompson import CaptureThompson\n",
    "import time\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing phis.\n",
      "Precomputation finished.\n"
     ]
    }
   ],
   "source": [
    "estimator = PoissonRateEstimator(\n",
    "    HierarchicalBorelSets(\n",
    "        d=2, interval=[(-1, 1), (-1, 1)], levels=8\n",
    "    ),  # 4^(8-1) cells in the lowest level\n",
    "    d=2,\n",
    "    kernel=KernelFunction(kernel_name=\"squared_exponential\", gamma=0.12, d=2),\n",
    "    max_intensity=10.0e10,  # maximal value of the rate function\n",
    "    min_intensity=0.1,  # minimal value of the rate function\n",
    "    basis_size_per_dim=10,  # number of basis functions along each axis\n",
    "    jitter=10e-3,\n",
    "    langevine_sampling_steps=200,  # langevin steps for sampling\n",
    "    optimization_library=\"torch\",\n",
    ")\n",
    "Num_data_points = 200\n",
    "name = \"./sensepy/sensepy/benchmarks/data/taxi_data.csv\"\n",
    "# borel set a square with boundaries [-1,1]^2\n",
    "D = BorelSet(2, bounds=torch.Tensor([[-1., 1.], [-1, 1]]).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BorelSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensepy/sensepy/benchmarks/data/taxi_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# borel set a square with boundaries [-1,1]^2\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m D \u001b[38;5;241m=\u001b[39m \u001b[43mBorelSet\u001b[49m(\u001b[38;5;241m2\u001b[39m, bounds\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor([[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m], [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mdouble())\n\u001b[1;32m      4\u001b[0m data, gdf \u001b[38;5;241m=\u001b[39m get_taxi_data(\u001b[38;5;241m200\u001b[39m, D)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BorelSet' is not defined"
     ]
    }
   ],
   "source": [
    "name = \"sensepy/sensepy/benchmarks/data/taxi_data.csv\"\n",
    "# borel set a square with boundaries [-1,1]^2\n",
    "D = BorelSet(2, bounds=torch.Tensor([[-1.0, 1.0], [-1, 1]]).double())\n",
    "data = get_taxi_data(200, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load data:  3.7317648999999946\n"
     ]
    }
   ],
   "source": [
    "# load data in the above format\n",
    "st = time.process_time()\n",
    "estimator.load_data(data)\n",
    "et = time.process_time()\n",
    "print(\"Time to load data: \", et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "Time to fit GP:  1.0818550999999985\n"
     ]
    }
   ],
   "source": [
    "# fit the Cox process by calculating MAP. Method is defined by estimator.estimator\n",
    "# it is set to penalized_likelihood, so we do the posterior GP approximation by\n",
    "# the sensing paper. Also estimator.feedback is set to count-record so no histogram\n",
    "# By default dual = True which means that data is split into buckets that\n",
    "# are given by the quadtree\n",
    "estimator.dual = True\n",
    "st = time.process_time()\n",
    "estimator.fit_gp()\n",
    "et = time.process_time()\n",
    "print(\"Time to fit GP: \", et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta = torch.full(size=(estimator.get_m(), 1), fill_value=1.0).view(-1).double()\n",
    "_, invGamma_half = estimator.cov(inverse=True)\n",
    "matrix = estimator.observations @ invGamma_half @ theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the approximation to the posterior using L-BFGS-B\n",
    "\n",
    "from autograd_minimize import minimize\n",
    "\n",
    "l, Lambda, u = estimator.get_constraints()\n",
    "_, invGamma_half = estimator.cov(inverse=True)\n",
    "\n",
    "eps = 1e-4\n",
    "theta0 = torch.full(size=(estimator.get_m(), 1), fill_value=1.0).view(-1).double()\n",
    "\n",
    "# Move to gpu\n",
    "theta0 = theta0.cuda()\n",
    "estimator.phis = estimator.phis.cuda()\n",
    "estimator.observations = estimator.observations.cuda()\n",
    "invGamma_half = invGamma_half.cuda()\n",
    "l = l.cuda()\n",
    "u = u.cuda()\n",
    "\n",
    "def objective(theta):\n",
    "    return -torch.sum(torch.log(estimator.observations @ invGamma_half @ theta + 1e-7)) + torch.sum(\n",
    "        estimator.phis @ invGamma_half @ theta) + estimator.s * 0.5 * torch.sum((invGamma_half @ theta) ** 2)\n",
    "\n",
    "res = minimize(objective, theta0.cpu().detach().numpy(), backend='torch', method='L-BFGS-B',\n",
    "                    bounds=(l[0] + eps, u[0]), precision='float64', tol=1e-8,\n",
    "                    options={'ftol': 1e-08,\n",
    "                                'gtol': 1e-08, 'eps': 1e-08,\n",
    "                                'maxfun': 15000, 'maxiter': 15000,\n",
    "                                'maxls': 20}, torch_device=str(theta0.device))\n",
    "\n",
    "estimator.rate = invGamma_half @ torch.from_numpy(res.x).cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move back to cpu\n",
    "estimator.phis = estimator.phis.cpu()\n",
    "estimator.observations = estimator.observations.cpu()\n",
    "estimator.rate = estimator.rate.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'left' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;66;03m# discretization\u001b[39;00m\n\u001b[1;32m      3\u001b[0m xtest \u001b[38;5;241m=\u001b[39m D\u001b[38;5;241m.\u001b[39mreturn_discretization(n)\n\u001b[0;32m----> 4\u001b[0m Map \u001b[38;5;241m=\u001b[39m BorelSet(d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, bounds\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mTensor([[\u001b[43mleft\u001b[49m, right], [down, up]])\u001b[38;5;241m.\u001b[39mdouble())\n\u001b[1;32m      5\u001b[0m xtest_orig \u001b[38;5;241m=\u001b[39m Map\u001b[38;5;241m.\u001b[39mreturn_discretization(n)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      7\u001b[0m f \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mrate_value(xtest)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'left' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotting the fitted Map \n",
    "n = 30 # discretization\n",
    "xtest = D.return_discretization(n)\n",
    "Map = BorelSet(d=2, bounds=torch.Tensor([[left, right], [down, up]]).double())\n",
    "xtest_orig = Map.return_discretization(n).numpy()\n",
    "\n",
    "f = estimator.rate_value(xtest)\n",
    "\n",
    "xx = xtest_orig[:, 0]\n",
    "yy = xtest_orig[:, 1]\n",
    "\n",
    "grid_x, grid_y = np.mgrid[min(xx):max(xx):100j, min(yy):max(yy):100j]\n",
    "grid_z_f = griddata((xx, yy), f[:, 0].detach().numpy(), (grid_x, grid_y), method='linear')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf.plot(ax=ax, color='red', figsize=(10, 10))\n",
    "cs = ax.contourf(grid_x, grid_y, grid_z_f, levels=20, alpha=0.5)\n",
    "ax.contour(cs, colors='k', alpha=0.5)\n",
    "ctx.add_basemap(ax, crs=gdf.crs.to_string())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
